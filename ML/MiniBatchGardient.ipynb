{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary Library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.datasets import load_diabetes\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes=load_diabetes()\n",
    "x=diabetes.data\n",
    "y=diabetes.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom class for MiniBatch Gradient Descent (MBGD) optimization\n",
    "class MiniBatch():\n",
    "\n",
    "    # Constructor method to initialize the learning rate (lr) and number of epochs and batch_size\n",
    "    def __init__(self, lr=0.1, epochs=100,batch_size=35):\n",
    "        self.coef_ = None  # Coefficients for the linear model (weights)\n",
    "        self.intercept_ = None  # Intercept (bias) term for the linear model\n",
    "        self.lr = lr  # Learning rate for gradient descent\n",
    "        self.epochs = epochs  # Number of iterations for training\n",
    "        self.batch_size=batch_size # batch_size\n",
    "    # Method to train the model on the training data using MBGD\n",
    "    def fitmodel(self, X_train, Y_train):\n",
    "        self.intercept_ = 0  # Initialize intercept as 0\n",
    "        self.coef_ = np.ones(X_train.shape[1])  # Initialize coefficients as ones\n",
    "\n",
    "        # Loop through the number of epochs\n",
    "        for i in range(self.epochs):\n",
    "            # Loop through each training sample\n",
    "            for j in range(X_train.shape[0]//self.batch_size):\n",
    "                # Randomly select an batch for MBGD calculation\n",
    "                id =random.sample(range(X_train.shape[0]),self.batch_size)\n",
    "\n",
    "                # Calculate the predicted value for the randomly selected sample\n",
    "                y_predicted = np.dot(X_train[id], self.coef_) + self.intercept_\n",
    "\n",
    "                # Compute the gradient (derivative) for the intercept term\n",
    "                intercept_der = -2 * np.mean(Y_train[id] - y_predicted)\n",
    "                # Update the intercept using the learning rate and gradient\n",
    "                self.intercept_ = self.intercept_ - (self.lr * intercept_der)\n",
    "\n",
    "                # Compute the gradient (derivative) for the coefficients\n",
    "                coef_der = -2 * np.dot((Y_train[id] - y_predicted), X_train[id])\n",
    "                # Update the coefficients using the learning rate and gradient\n",
    "                self.coef_ = self.coef_ - (self.lr * coef_der)\n",
    "\n",
    "        # Print the final intercept and coefficients after training\n",
    "        print(self.intercept_, self.coef_)\n",
    "\n",
    "    # Method to make predictions on test data using the trained model\n",
    "    def predict(self, X_test):\n",
    "        # Return the predicted values by applying the linear model (dot product)\n",
    "        return np.dot(X_test, self.coef_) + self.intercept_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbg=MiniBatch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153.76776896051905 [  32.42122624 -245.85698709  575.46492656  372.15983776 -165.62528461\n",
      "  -57.3088091  -193.09911929  165.71447371  354.12829451   34.05803066]\n"
     ]
    }
   ],
   "source": [
    "mbg.fitmodel(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_MBGD=mbg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4758455858749049"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,y_MBGD)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
